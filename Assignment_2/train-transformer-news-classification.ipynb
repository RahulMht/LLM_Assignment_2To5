{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf6092b",
   "metadata": {},
   "source": [
    "**Transformer-from-Scratch: News Category Classifier**\n",
    "\n",
    "1. Ingests & cleans the AG News corpus, tokenizes text, and builds a bespoke vocabulary.  \n",
    "2. Implements sinusoidal position embeddings and a stacked multi-head self-attention encoder from first principles.  \n",
    "3. Adds a lightweight classification head and trains end-to-end to predict one of four news sections.  \n",
    "4. Validates accuracy, printing tensor shapes at every stage for sanity checks.\n",
    "\n",
    "---\n",
    "\n",
    "### Supporting technical theory\n",
    "\n",
    "#### 1 · Tokenization & Embeddings  \n",
    "Tokens are mapped to vectors **E** ∈ ℝ^{|V|×d}. Fixed sinusoidal encodings **P** supply sequence order, so the input to the encoder is **X** = **E** + **P**.\n",
    "\n",
    "#### 2 · Multi-Head Self-Attention  \n",
    "For each head *h*:  \n",
    "\\[\n",
    "\\mathrm{Attention}(Q,K,V)=\\operatorname{softmax}\\!\\left(\\frac{QK^{\\top}}{\\sqrt{d_k}}\\right)V\n",
    "\\]  \n",
    "Parallel heads let the model focus on multiple relational patterns; their outputs are concatenated and linearly projected.\n",
    "\n",
    "#### 3 · Residual Add + LayerNorm  \n",
    "Every sub-layer is wrapped as \\( \\mathrm{LayerNorm}(x + \\mathrm{Sublayer}(x)) \\), stabilizing statistics and preserving gradient flow in deep stacks.\n",
    "\n",
    "#### 4 · Position-Wise Feed-Forward  \n",
    "A two-layer MLP (ReLU/GELU) is applied identically to each time-step, enriching token-level representations and boosting model capacity.\n",
    "\n",
    "> *Symbols:* \\( |V| \\) – vocab size, \\( d \\) – hidden size, \\( d_k \\) – per-head key/query dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48590840",
   "metadata": {
    "_cell_guid": "8a656256-11b0-4c83-a277-103f9dca342d",
    "_uuid": "7144b017-73ea-4fce-8e7b-bc44165d0444",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:23:51.572333Z",
     "iopub.status.busy": "2025-06-26T19:23:51.571575Z",
     "iopub.status.idle": "2025-06-26T19:23:53.134621Z",
     "shell.execute_reply": "2025-06-26T19:23:53.133753Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.574173,
     "end_time": "2025-06-26T19:23:53.136076",
     "exception": false,
     "start_time": "2025-06-26T19:23:51.561903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02930045",
   "metadata": {
    "_cell_guid": "2d41563e-7753-46fc-864b-e7bd883c8391",
    "_uuid": "f7d6b354-c8ac-4bd0-ac6c-c90f977ce13e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.007588,
     "end_time": "2025-06-26T19:23:53.151735",
     "exception": false,
     "start_time": "2025-06-26T19:23:53.144147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1cea85b",
   "metadata": {
    "_cell_guid": "915998a8-05b2-4622-bf7b-a8693130a186",
    "_uuid": "e68dfc91-d2be-436c-bd25-78e5f0098efb",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:23:53.166884Z",
     "iopub.status.busy": "2025-06-26T19:23:53.166555Z",
     "iopub.status.idle": "2025-06-26T19:23:55.875641Z",
     "shell.execute_reply": "2025-06-26T19:23:55.875008Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.71803,
     "end_time": "2025-06-26T19:23:55.876815",
     "exception": false,
     "start_time": "2025-06-26T19:23:53.158785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>Carla K. Johnson, AP</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>Mary Papenfuss</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>Nina Golgowski</td>\n",
       "      <td>2022-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
       "1  https://www.huffpost.com/entry/american-airlin...   \n",
       "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
       "3  https://www.huffpost.com/entry/funniest-parent...   \n",
       "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
       "\n",
       "                                            headline   category  \\\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
       "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
       "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
       "\n",
       "                                   short_description               authors  \\\n",
       "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
       "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
       "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
       "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
       "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
       "\n",
       "         date  \n",
       "0  2022-09-23  \n",
       "1  2022-09-23  \n",
       "2  2022-09-23  \n",
       "3  2022-09-23  \n",
       "4  2022-09-22  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the file\n",
    "with open('/kaggle/input/news-category-dataset/News_Category_Dataset_v3.json') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "#Convert that into Dataframe or easier inspection\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# View the first item\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e21d2c3f",
   "metadata": {
    "_cell_guid": "b84b61d9-8493-49dd-ab96-8bcc098e13a4",
    "_uuid": "1f0d28da-ce9b-4b50-8a9f-57989cd0ce57",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:23:55.892588Z",
     "iopub.status.busy": "2025-06-26T19:23:55.892395Z",
     "iopub.status.idle": "2025-06-26T19:23:55.896740Z",
     "shell.execute_reply": "2025-06-26T19:23:55.896074Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013383,
     "end_time": "2025-06-26T19:23:55.897893",
     "exception": false,
     "start_time": "2025-06-26T19:23:55.884510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209527"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Number of data\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "939b5508",
   "metadata": {
    "_cell_guid": "4b5f6241-8872-4538-b955-e8209c11cef1",
    "_uuid": "64e4dc1f-d1d3-4a15-89b7-3d784c5bbef6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:23:55.914389Z",
     "iopub.status.busy": "2025-06-26T19:23:55.913472Z",
     "iopub.status.idle": "2025-06-26T19:23:55.939408Z",
     "shell.execute_reply": "2025-06-26T19:23:55.938919Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034922,
     "end_time": "2025-06-26T19:23:55.940536",
     "exception": false,
     "start_time": "2025-06-26T19:23:55.905614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Take only headline and short_description\n",
    "df = df[['headline', 'short_description', 'category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5bf81a3",
   "metadata": {
    "_cell_guid": "e942321c-9f57-47ab-b573-2b1594690471",
    "_uuid": "baf80f4d-a448-4e0f-93dc-e32b4c87b693",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:23:55.955470Z",
     "iopub.status.busy": "2025-06-26T19:23:55.955290Z",
     "iopub.status.idle": "2025-06-26T19:23:56.067191Z",
     "shell.execute_reply": "2025-06-26T19:23:56.066378Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.120931,
     "end_time": "2025-06-26T19:23:56.068615",
     "exception": false,
     "start_time": "2025-06-26T19:23:55.947684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Combine them both in single columns\n",
    "df['news'] = df['headline'] + ' - ' + df['short_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a38cf251",
   "metadata": {
    "_cell_guid": "c24cf0cb-9e19-4c09-84b3-5b69697e9da6",
    "_uuid": "964807a8-0a14-47f5-9f23-246eeb100e99",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:23:56.084754Z",
     "iopub.status.busy": "2025-06-26T19:23:56.084154Z",
     "iopub.status.idle": "2025-06-26T19:23:56.114451Z",
     "shell.execute_reply": "2025-06-26T19:23:56.113840Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.03918,
     "end_time": "2025-06-26T19:23:56.115536",
     "exception": false,
     "start_time": "2025-06-26T19:23:56.076356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COMEDY</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PARENTING</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                               news\n",
       "0  U.S. NEWS  Over 4 Million Americans Roll Up Sleeves For O...\n",
       "1  U.S. NEWS  American Airlines Flyer Charged, Banned For Li...\n",
       "2     COMEDY  23 Of The Funniest Tweets About Cats And Dogs ...\n",
       "3  PARENTING  The Funniest Tweets From Parents This Week (Se...\n",
       "4  U.S. NEWS  Woman Who Called Cops On Black Bird-Watcher Lo..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove the headline and short_description\n",
    "df = df.drop(columns = ['headline', 'short_description'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aefd0f81",
   "metadata": {
    "_cell_guid": "61f59b9a-a2d1-45a5-bb52-dbd1b8bc45fa",
    "_uuid": "1c4335bf-946e-437c-8402-3dae630e7bfd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:23:56.132397Z",
     "iopub.status.busy": "2025-06-26T19:23:56.131715Z",
     "iopub.status.idle": "2025-06-26T19:23:56.136405Z",
     "shell.execute_reply": "2025-06-26T19:23:56.135814Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013616,
     "end_time": "2025-06-26T19:23:56.137366",
     "exception": false,
     "start_time": "2025-06-26T19:23:56.123750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters - Health experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "World Cup Captains Want To Wear Rainbow Armbands In Qatar - FIFA has come under pressure from several European soccer federations who want to support a human rights campaign against discrimination at the World Cup.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Golden Globes Returning To NBC In January After Year Off-Air - For the past 18 months, Hollywood has effectively boycotted the Globes after reports that the HFPA’s 87 members of non-American journalists included no Black members.\n"
     ]
    }
   ],
   "source": [
    "print(df['news'][0])\n",
    "print('-' * 110)\n",
    "print(df['news'][10])\n",
    "print('-' * 110)\n",
    "print(df['news'][20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ac737",
   "metadata": {
    "papermill": {
     "duration": 0.007367,
     "end_time": "2025-06-26T19:23:56.152424",
     "exception": false,
     "start_time": "2025-06-26T19:23:56.145057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cleaning the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3a4190f",
   "metadata": {
    "_cell_guid": "341484e5-f600-4bc3-85e1-0b47d7725253",
    "_uuid": "ad8cdafd-9e63-42a3-b67d-a6f9dc6d316e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:23:56.167517Z",
     "iopub.status.busy": "2025-06-26T19:23:56.167311Z",
     "iopub.status.idle": "2025-06-26T19:23:59.732040Z",
     "shell.execute_reply": "2025-06-26T19:23:59.731176Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.573738,
     "end_time": "2025-06-26T19:23:59.733354",
     "exception": false,
     "start_time": "2025-06-26T19:23:56.159616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over 4 million americans roll up sleeves for omicrontargeted covid boosters health experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the us ordered for the fall\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "world cup captains want to wear rainbow armbands in qatar fifa has come under pressure from several european soccer federations who want to support a human rights campaign against discrimination at the world cup\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "golden globes returning to nbc in january after year offair for the past 18 months hollywood has effectively boycotted the globes after reports that the hfpas 87 members of nonamerican journalists included no black members\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove punctuation and special characters (except words and spaces)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['news'] = df['news'].apply(clean_text)\n",
    "\n",
    "print(df['news'][0])\n",
    "print('-' * 110)\n",
    "print(df['news'][10])\n",
    "print('-' * 110)\n",
    "print(df['news'][20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed09b42",
   "metadata": {
    "papermill": {
     "duration": 0.007136,
     "end_time": "2025-06-26T19:23:59.748293",
     "exception": false,
     "start_time": "2025-06-26T19:23:59.741157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build the Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ddbca43",
   "metadata": {
    "_cell_guid": "5e2cc1d6-cf3c-4dbe-8ee6-b168df4453d4",
    "_uuid": "763abf99-d1da-4792-a4dc-27fa104b8dd3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:23:59.763889Z",
     "iopub.status.busy": "2025-06-26T19:23:59.763638Z",
     "iopub.status.idle": "2025-06-26T19:24:01.698520Z",
     "shell.execute_reply": "2025-06-26T19:24:01.697765Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.944094,
     "end_time": "2025-06-26T19:24:01.699801",
     "exception": false,
     "start_time": "2025-06-26T19:23:59.755707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Building the Vocab\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# 1)Build vocab \n",
    "def build_vocab(texts, min_freq = 1):\n",
    "    \"\"\"\n",
    "    Build vocabulary from a list of texts.\n",
    "\n",
    "    Args:\n",
    "        texts (list of str): List of text samples.\n",
    "        min_freq (int): Minimum frequency for a word to be included.\n",
    "\n",
    "    Returns:\n",
    "        word2idx (dict): Mapping from word to unique integer index.\n",
    "    \"\"\"\n",
    "    # Count token frequencies\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        counter.update(tokens)\n",
    "    \n",
    "    # Filter tokens by frequency threshold\n",
    "    vocab_tokens = [token for token, freq in counter.items() if freq >= min_freq]\n",
    "    \n",
    "    # Add special tokens\n",
    "    special_tokens = ['<PAD>', '<UNK>']\n",
    "    \n",
    "    # Final vocabulary: special tokens + sorted frequent tokens\n",
    "    vocab = special_tokens + sorted(vocab_tokens)\n",
    "    \n",
    "    # Create token to index mapping\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    \n",
    "    return word2idx\n",
    "\n",
    "# Encode a single text to token IDs with padding/truncation\n",
    "def encode_text(text, word2idx, max_len=32):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    ids = [word2idx.get(token, word2idx['<UNK>']) for token in tokens]\n",
    "    if len(ids) > max_len:\n",
    "        ids = ids[:max_len]\n",
    "    else:\n",
    "        ids += [word2idx['<PAD>']] * (max_len - len(ids))\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad3a800",
   "metadata": {
    "papermill": {
     "duration": 0.007512,
     "end_time": "2025-06-26T19:24:01.715272",
     "exception": false,
     "start_time": "2025-06-26T19:24:01.707760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Making the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9420a946",
   "metadata": {
    "_cell_guid": "d8f0272c-ca1d-4a2f-b4be-93f0ce54c7fc",
    "_uuid": "f4fb58f2-ac19-46cc-bd85-fd65a84ae4a3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:01.731071Z",
     "iopub.status.busy": "2025-06-26T19:24:01.730672Z",
     "iopub.status.idle": "2025-06-26T19:24:05.901087Z",
     "shell.execute_reply": "2025-06-26T19:24:05.900403Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.179873,
     "end_time": "2025-06-26T19:24:05.902528",
     "exception": false,
     "start_time": "2025-06-26T19:24:01.722655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "import torch\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset class for news text classification.\n",
    "\n",
    "    Args:\n",
    "        texts (List[str]): List of input text samples (e.g., headlines or descriptions).\n",
    "        labels (List[int]): Corresponding list of integer class labels.\n",
    "        word2idx (dict): Vocabulary mapping from tokens to integer indices.\n",
    "        max_len (int): Maximum sequence length. Texts will be padded or truncated to this length.\n",
    "    \"\"\"\n",
    "    def __init__(self, texts, labels, word2idx, max_len=32):\n",
    "        self.texts = texts              # Raw input texts\n",
    "        self.labels = labels            # Integer class labels\n",
    "        self.word2idx = word2idx        # Token-to-index vocabulary\n",
    "        self.max_len = max_len          # Max token length per sample\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve and encode a single example by index\n",
    "        encoded_text = encode_text(self.texts[idx], self.word2idx, self.max_len)\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Return tensors for model consumption\n",
    "        return torch.tensor(encoded_text, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b4be6f",
   "metadata": {
    "_cell_guid": "453bc7d2-a029-4fd8-863c-415cf8fff74a",
    "_uuid": "92f16628-acd9-4943-8888-c2237c433b24",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:05.919393Z",
     "iopub.status.busy": "2025-06-26T19:24:05.919045Z",
     "iopub.status.idle": "2025-06-26T19:24:05.961786Z",
     "shell.execute_reply": "2025-06-26T19:24:05.961175Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.052541,
     "end_time": "2025-06-26T19:24:05.963229",
     "exception": false,
     "start_time": "2025-06-26T19:24:05.910688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category    0\n",
       "news        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if there is a null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42abe688",
   "metadata": {
    "_cell_guid": "b8e93844-6e0a-45b3-95f1-67a7da4eb1b4",
    "_uuid": "afc63d16-5ca9-4a1e-84dc-0e491b255173",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:05.980537Z",
     "iopub.status.busy": "2025-06-26T19:24:05.980296Z",
     "iopub.status.idle": "2025-06-26T19:24:06.014203Z",
     "shell.execute_reply": "2025-06-26T19:24:06.013339Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.043662,
     "end_time": "2025-06-26T19:24:06.015357",
     "exception": false,
     "start_time": "2025-06-26T19:24:05.971695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "POLITICS          35602\n",
       "WELLNESS          17945\n",
       "ENTERTAINMENT     17362\n",
       "TRAVEL             9900\n",
       "STYLE & BEAUTY     9814\n",
       "PARENTING          8791\n",
       "HEALTHY LIVING     6694\n",
       "QUEER VOICES       6347\n",
       "FOOD & DRINK       6340\n",
       "BUSINESS           5992\n",
       "COMEDY             5400\n",
       "SPORTS             5077\n",
       "BLACK VOICES       4583\n",
       "HOME & LIVING      4320\n",
       "PARENTS            3955\n",
       "THE WORLDPOST      3664\n",
       "WEDDINGS           3653\n",
       "WOMEN              3572\n",
       "CRIME              3562\n",
       "IMPACT             3484\n",
       "DIVORCE            3426\n",
       "WORLD NEWS         3299\n",
       "MEDIA              2944\n",
       "WEIRD NEWS         2777\n",
       "GREEN              2622\n",
       "WORLDPOST          2579\n",
       "RELIGION           2577\n",
       "STYLE              2254\n",
       "SCIENCE            2206\n",
       "TECH               2104\n",
       "TASTE              2096\n",
       "MONEY              1756\n",
       "ARTS               1509\n",
       "ENVIRONMENT        1444\n",
       "FIFTY              1401\n",
       "GOOD NEWS          1398\n",
       "U.S. NEWS          1377\n",
       "ARTS & CULTURE     1339\n",
       "COLLEGE            1144\n",
       "LATINO VOICES      1130\n",
       "CULTURE & ARTS     1074\n",
       "EDUCATION          1014\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many are their in each category\n",
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633b16d5",
   "metadata": {
    "papermill": {
     "duration": 0.049281,
     "end_time": "2025-06-26T19:24:06.072528",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.023247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c40ba90b",
   "metadata": {
    "_cell_guid": "67470224-0c11-47cf-bba8-111b44768a2a",
    "_uuid": "1592a6ab-ebb8-42d7-a96a-d5016f4ca06c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:06.088551Z",
     "iopub.status.busy": "2025-06-26T19:24:06.088308Z",
     "iopub.status.idle": "2025-06-26T19:24:06.156128Z",
     "shell.execute_reply": "2025-06-26T19:24:06.155176Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.077343,
     "end_time": "2025-06-26T19:24:06.157412",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.080069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARTS' 'ARTS & CULTURE' 'BLACK VOICES' 'BUSINESS' 'COLLEGE' 'COMEDY'\n",
      " 'CRIME' 'CULTURE & ARTS' 'DIVORCE' 'EDUCATION' 'ENTERTAINMENT'\n",
      " 'ENVIRONMENT' 'FIFTY' 'FOOD & DRINK' 'GOOD NEWS' 'GREEN' 'HEALTHY LIVING'\n",
      " 'HOME & LIVING' 'IMPACT' 'LATINO VOICES' 'MEDIA' 'MONEY' 'PARENTING'\n",
      " 'PARENTS' 'POLITICS' 'QUEER VOICES' 'RELIGION' 'SCIENCE' 'SPORTS' 'STYLE'\n",
      " 'STYLE & BEAUTY' 'TASTE' 'TECH' 'THE WORLDPOST' 'TRAVEL' 'U.S. NEWS'\n",
      " 'WEDDINGS' 'WEIRD NEWS' 'WELLNESS' 'WOMEN' 'WORLD NEWS' 'WORLDPOST']\n",
      "label\n",
      "24    35602\n",
      "38    17945\n",
      "10    17362\n",
      "34     9900\n",
      "30     9814\n",
      "22     8791\n",
      "16     6694\n",
      "25     6347\n",
      "13     6340\n",
      "3      5992\n",
      "5      5400\n",
      "28     5077\n",
      "2      4583\n",
      "17     4320\n",
      "23     3955\n",
      "33     3664\n",
      "36     3653\n",
      "39     3572\n",
      "6      3562\n",
      "18     3484\n",
      "8      3426\n",
      "40     3299\n",
      "20     2944\n",
      "37     2777\n",
      "15     2622\n",
      "41     2579\n",
      "26     2577\n",
      "29     2254\n",
      "27     2206\n",
      "32     2104\n",
      "31     2096\n",
      "21     1756\n",
      "0      1509\n",
      "11     1444\n",
      "12     1401\n",
      "14     1398\n",
      "35     1377\n",
      "1      1339\n",
      "4      1144\n",
      "19     1130\n",
      "7      1074\n",
      "9      1014\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['category'])\n",
    "print(le.classes_)  # array of category names in order\n",
    "print(df['label'].value_counts())  # distribution of encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eee504fc",
   "metadata": {
    "_cell_guid": "a8abcf0f-02b1-4cfe-adf7-bf5156feaf0c",
    "_uuid": "8cf30736-7cab-4bf4-861b-ea6758cbe0d0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:06.175288Z",
     "iopub.status.busy": "2025-06-26T19:24:06.175073Z",
     "iopub.status.idle": "2025-06-26T19:24:06.238009Z",
     "shell.execute_reply": "2025-06-26T19:24:06.237296Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.072978,
     "end_time": "2025-06-26T19:24:06.239174",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.166196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce23894d",
   "metadata": {
    "_cell_guid": "fe226057-59cd-47dc-a038-de4b22688777",
    "_uuid": "1db8884e-a3c2-4484-8ee2-70cd33e7d704",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:06.256157Z",
     "iopub.status.busy": "2025-06-26T19:24:06.255933Z",
     "iopub.status.idle": "2025-06-26T19:24:06.454177Z",
     "shell.execute_reply": "2025-06-26T19:24:06.453519Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.208088,
     "end_time": "2025-06-26T19:24:06.455486",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.247398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1509  1339  4583  5992  1144  5400  3562  1074  3426  1014 17362  1444\n",
      "  1401  6340  1398  2622  6694  4320  3484  1130  2944  1756  8791  3955\n",
      " 35602  6347  2577  2206  5077  2254  9814  2096  2104  3664  9900  1377\n",
      "  3653  2777 17945  3572  3299  2579]\n"
     ]
    }
   ],
   "source": [
    "# Calculate class counts\n",
    "counts = df['label'].value_counts().sort_index().values  # sorted by label index\n",
    "print(counts)\n",
    "\n",
    "# Compute class weights inversely proportional to frequency\n",
    "class_weights = 1.0 / counts\n",
    "class_weights = class_weights / class_weights.sum() * len(class_weights)  # normalize\n",
    "\n",
    "# Convert to torch tensor\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# Use in loss\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa89b03",
   "metadata": {
    "papermill": {
     "duration": 0.007742,
     "end_time": "2025-06-26T19:24:06.471498",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.463756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Input Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f12bd8",
   "metadata": {
    "papermill": {
     "duration": 0.007516,
     "end_time": "2025-06-26T19:24:06.486665",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.479149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's focus on the Encoder Part for now:\n",
    "\n",
    "### Transformer Encoder\n",
    "\n",
    "At first you can see that we have Input Embedding and the Positional Encoding so let's talk about that,\n",
    "\n",
    "**Embedding** -> So, we know that the first thing we do is tokenize and we recieve the set's of discrete tokens and embedding's job is to change the set of discrete tokens into the continous vector representation.\n",
    "\n",
    "Why the need to do this?\n",
    "Because, Transformer is the neural network and they understand the numbers and not the words, so we need to change them to the numerical representation forms such that they captures the semantic meaning and context.\n",
    "\n",
    "The transformer architecture starts with embedding sequences as vectors, and then encoding each token's position in the sequence so that tokens can be processed in parallel.\n",
    "\n",
    "Suppose, we have three tokens \n",
    "[\"Cat\", \"Dog\", \"Fish\"]\n",
    "\n",
    "We know that each token have their own unique ID in the modle vocab which the model recognize. If we embed them using the embedding layers we get the embedding vector.The length of this vector is also referred to as the number of dimensions, or dimensionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac64fe54",
   "metadata": {
    "_cell_guid": "102d6633-08b6-4f15-b011-6a288b902656",
    "_uuid": "589dcc18-5085-4055-a2cd-f6971af28c8d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:06.503687Z",
     "iopub.status.busy": "2025-06-26T19:24:06.503116Z",
     "iopub.status.idle": "2025-06-26T19:24:06.508082Z",
     "shell.execute_reply": "2025-06-26T19:24:06.507389Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014844,
     "end_time": "2025-06-26T19:24:06.509220",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.494376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class InputEmbeddings(nn.Module):\n",
    "    \"\"\"\n",
    "    Converts token indices into dense vector embeddings and scales them.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of the vocabulary (number of unique tokens).\n",
    "        d_model (int): Dimensionality of the embedding vectors (also the model's hidden size).\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size: int, d_model: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model                  # Embedding dimension (same as model hidden size)\n",
    "        self.vocab_size = vocab_size            # Total number of tokens in vocabulary\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)  # Learnable embedding table\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): Tensor of token indices of shape (batch_size, seq_len)\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Embedded and scaled tensor of shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        # Multiply by sqrt(d_model) as recommended in the Transformer paper to help with convergence\n",
    "        return self.embedding(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae353751",
   "metadata": {
    "papermill": {
     "duration": 0.007714,
     "end_time": "2025-06-26T19:24:06.524991",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.517277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Positional Encoding** : It is added to give the model information about the position of each word in a sequence.\n",
    "\n",
    "Why the need of this? Because The word \"ate\" in \"The cat ate the fish\" is different from \"ate\" in \"Ate the cat the fish?\" — the order matters.\n",
    "\n",
    "The positional Encoding are generated using the special encoding equation, where the sin is use for the even embedding values and cos is used for odd emedding values\n",
    "\n",
    "The positional encoding for position `pos` and dimension `i` is defined as:\n",
    "\n",
    "$$\n",
    "\\text{PE}_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{\\frac{2i}{d}}}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{PE}_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{\\frac{2i}{d}}}\\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( pos \\) is the position in the sequence,\n",
    "- \\( i \\) is the dimension index,\n",
    "- \\( d \\) is the total embedding dimension.\n",
    "\n",
    "Sin and Cosine are the periodic functions who have their values between -1 and 1.\n",
    "\n",
    "Why do we used them?\n",
    "\n",
    "**Provide the unique patterns for each position**\n",
    "1. The combination of sin and cos with different frequencies ensures that the each position has a unique encoding vector.\n",
    "2. No two positions have the same encoding, and nearby positions have similar vectors, which helps the model recognize local context.\n",
    "\n",
    "**Captures relative position information**\n",
    "1. The sinusoidal form makes it easy for the model to learn the relative positions between words.\n",
    "2. For example, PE(pos + k) can be expressed as a linear function of PE(pos), allowing the model to infer order differences like “word A is 2 steps ahead of word B”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "067e8b31",
   "metadata": {
    "_cell_guid": "adb06e68-4c11-46df-b45d-f69c3fdf45e0",
    "_uuid": "83a000ad-4908-4ac3-8062-6437e904206e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:06.541648Z",
     "iopub.status.busy": "2025-06-26T19:24:06.541443Z",
     "iopub.status.idle": "2025-06-26T19:24:06.546958Z",
     "shell.execute_reply": "2025-06-26T19:24:06.546281Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015144,
     "end_time": "2025-06-26T19:24:06.548089",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.532945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements the sinusoidal positional encoding from the Transformer paper:\n",
    "    \"Attention is All You Need\" (Vaswani et al. 2017).\n",
    "\n",
    "    This adds information about token positions to the input embeddings, \n",
    "    enabling the model to capture order without recurrence.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Dimensionality of the model/embedding.\n",
    "        max_seq_length (int): Maximum sequence length supported.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize a matrix of shape (max_seq_length, d_model)\n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "\n",
    "        # Position indices (0 to max_seq_length-1) shaped as (max_seq_length, 1)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        # Compute the div_term (frequency) for the sinusoidal functions.\n",
    "        # Only half (every 2nd dim) because sin and cos alternate over even and odd dims\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        # Apply sine to even indices in the array; 2i\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "\n",
    "        # Apply cosine to odd indices in the array; 2i+1\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # Register as a buffer (non-learnable), adds a batch dimension for broadcasting\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))  # shape: (1, max_seq_length, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Adds positional encoding to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input of shape (batch_size, seq_len, d_model)\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Positionally encoded input of the same shape\n",
    "        \"\"\"\n",
    "        # Add positional encoding to the input\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64917d5",
   "metadata": {
    "papermill": {
     "duration": 0.007532,
     "end_time": "2025-06-26T19:24:06.563926",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.556394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Multi-Head Attention\n",
    "\n",
    "Before that, What is self Attention?\n",
    "\n",
    "Self Attention is what enables the transformers to identify the relationship between tokens and to determine and focus on the most relevant ones. It allows a model to look at other positions in the same input sequence when encoding a word — hence the name \"self\" attention.\n",
    "\n",
    "Self-attention determines:\n",
    "“Which other words in the sentence should I pay attention to when understanding this word?”\\\n",
    "\n",
    "Example:\n",
    "Take the sentence:\n",
    "\n",
    "“The cat sat on the mat because it was warm.”\n",
    "\n",
    "To understand what “it” refers to, self-attention helps the model focus on “cat” or “mat” rather than every word equally. The model figures this out on its own during training.\n",
    "\n",
    "We know that each input word is converted into the embedding right? So then each embedding is project into the three different matrices known as Q, K and V.\n",
    "\n",
    "Q : Query (indicates what each \"token\" is looking for in another token)\n",
    "\n",
    "V : Value (Actual content to be aggregated or weighted)\n",
    "\n",
    "K : Key (Represents the content of each token that other token might find relevant )\n",
    "\n",
    "using seprate linear transformations with learned weights.\n",
    "\n",
    "🧠 Analogy: Job Search Example\n",
    "Imagine you're trying to hire someone:\n",
    "\n",
    "    - Your Query (Q) is the job requirement.\n",
    "\n",
    "    - Each candidate has a Key (K) = their resume.\n",
    "\n",
    "    - The actual Value (V) is what you’d get if you hired them.\n",
    "\n",
    "You compare your Query to all the Keys (resumes) to get scores, then use those scores to weigh the Values (candidates’ actual skills).\n",
    "\n",
    "Values are based on the attention-scores, which are computed by doing the dot-product of the Key and Query matrices\n",
    "So, Attention scores = Q-K similarity(dot - product) from where we get the attention scores(n*n)\n",
    "\n",
    "From the attention scores we apply the Softmax to get the attention weights.\n",
    "\n",
    "so, below is the clear image to show\n",
    "\n",
    "\n",
    "Example : \n",
    "\"orange is my favorite fruit,\" the tokens \"favorite\" and \"fruit\" receive the highest attention when processing \"orange,\" as they directly influence its context and meaning. The model interprets \"orange\" as a favored fruit rather than a color or other meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e022f",
   "metadata": {
    "papermill": {
     "duration": 0.007587,
     "end_time": "2025-06-26T19:24:06.579210",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.571623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ⚙️ Step-by-step:\n",
    "\n",
    "#### 1. Compute Dot Products:  $Q \\cdot K^T$\n",
    "\n",
    "This gives a score of how much attention word A should pay to word B.\n",
    "\n",
    "#### 2. Scale and Apply Softmax:\n",
    "\n",
    "$$\n",
    "\\text{Attention\\_weights} = \\text{softmax} \\left( \\frac{QK^T}{\\sqrt{d_k}} \\right)\n",
    "$$\n",
    "\n",
    "This normalizes the scores into probabilities.\n",
    "\n",
    "#### 3. Multiply with V:\n",
    "\n",
    "$$\n",
    "\\text{Output} = \\text{Attention\\_weights} \\cdot V\n",
    "$$\n",
    "\n",
    "Each word’s final output is a **weighted sum of all the Value vectors**, based on attention.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d28b326",
   "metadata": {
    "papermill": {
     "duration": 0.007685,
     "end_time": "2025-06-26T19:24:06.594570",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.586885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Multi Attention head\n",
    "\n",
    "Multi-Head Attention is an advanced form of self-attention used in Transformers. Instead of calculating just one set of attention outputs (with one Q/K/V), it creates multiple \"attention heads\" — each learning different relationships or features in the input.\n",
    "\n",
    "⚙️ Why do we need Multi-Head Attention?\n",
    "\n",
    "A single self-attention layer may focus too narrowly. With multi-head attention:\n",
    "\n",
    "- Each head looks at the sequence from a different perspective.\n",
    "\n",
    "- Some heads may learn syntax (e.g., subject-verb links), others learn semantics (e.g., coreference, word meaning).\n",
    "\n",
    "- This makes the model much more expressive.\n",
    "\n",
    "The resulting embeddings capture token meaning, positional encoding, and contextual relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5187599c",
   "metadata": {
    "_cell_guid": "f43106a1-235a-4e27-9d59-2a874bd93524",
    "_uuid": "66862473-66f0-46a8-be89-753478f40ed5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:06.610957Z",
     "iopub.status.busy": "2025-06-26T19:24:06.610722Z",
     "iopub.status.idle": "2025-06-26T19:24:06.619350Z",
     "shell.execute_reply": "2025-06-26T19:24:06.618660Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018217,
     "end_time": "2025-06-26T19:24:06.620510",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.602293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head self-attention mechanism as described in the \"Attention is All You Need\" paper.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Total dimensionality of the model.\n",
    "        num_heads (int): Number of parallel attention heads.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.head_dim = d_model // num_heads  # Dimension per head\n",
    "\n",
    "        # Linear transformations for query, key, and value (no bias for attention projection)\n",
    "        self.query_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.key_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.value_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "        # Final linear layer after concatenating all heads\n",
    "        self.output_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        Split the embedding into multiple heads.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): shape (batch_size, seq_len, d_model)\n",
    "\n",
    "        Returns:\n",
    "            Tensor: shape (batch_size, num_heads, seq_len, head_dim)\n",
    "        \"\"\"\n",
    "        seq_length = x.size(1)\n",
    "        x = x.reshape(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "        return x.permute(0, 2, 1, 3)  # move num_heads before seq_len\n",
    "\n",
    "    def compute_attention(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        Compute scaled dot-product attention.\n",
    "\n",
    "        Returns:\n",
    "            context vector after attention, shape: (batch_size, num_heads, seq_len, head_dim)\n",
    "        \"\"\"\n",
    "        # Shape: (batch_size, num_heads, seq_len, seq_len)\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "\n",
    "        # Apply mask (if provided): mask shape should match scores\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attention_weights = F.softmax(scores, dim=-1)  # softmax along last dimension\n",
    "        return torch.matmul(attention_weights, value)  # context\n",
    "\n",
    "    def combine_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        Combine the heads back to a single tensor.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): shape (batch_size, num_heads, seq_len, head_dim)\n",
    "\n",
    "        Returns:\n",
    "            Tensor: shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()  # (batch_size, seq_len, num_heads, head_dim)\n",
    "        return x.view(batch_size, -1, self.d_model)  # combine last two dims\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Apply linear transformations\n",
    "        query = self.query_linear(query)\n",
    "        key = self.key_linear(key)\n",
    "        value = self.value_linear(value)\n",
    "\n",
    "        # Split into heads\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # Apply attention on all heads\n",
    "        attn_output = self.compute_attention(query, key, value, mask)\n",
    "\n",
    "        # Combine heads and pass through final linear layer\n",
    "        output = self.combine_heads(attn_output, batch_size)\n",
    "\n",
    "        return self.output_linear(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbb644b",
   "metadata": {
    "papermill": {
     "duration": 0.007805,
     "end_time": "2025-06-26T19:24:06.636385",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.628580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## FeedForward SubLayer\n",
    "\n",
    "After the Multi-Head Attention layer in a Transformer block, there's a FeedForward Neural Network (FFN) layer, also known as the FeedForward SubLayer. It adds non-linearity and transformation to each token independently.\n",
    "\n",
    "📌 Why It’s Used\n",
    "\n",
    "While attention layers let tokens communicate, the FFN lets each token transform itself — enriching its internal representation after it has “heard” from others.\n",
    "\n",
    "Our FeedForwardSublayer class contains two fully connected linear layers separated by a ReLU activation. \n",
    "\n",
    "Notice we use a dimension d_ff between linear layers, typically different from the embedding dimension used throughout the model to further facilitate capturing complex patterns. The forward method applies the forward pass to the attention mechanism outputs, passing them through the layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd4a8ffa",
   "metadata": {
    "_cell_guid": "8befc9e5-c006-4b62-b999-9d0f94e7308e",
    "_uuid": "042bd51b-9d7d-4178-8af6-dfee4b1be82f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:06.652608Z",
     "iopub.status.busy": "2025-06-26T19:24:06.652380Z",
     "iopub.status.idle": "2025-06-26T19:24:06.656733Z",
     "shell.execute_reply": "2025-06-26T19:24:06.656079Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013593,
     "end_time": "2025-06-26T19:24:06.657757",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.644164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FeedForwardSubLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Position-wise Feed-Forward Network used in Transformer blocks.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Input and output dimensionality (same as the embedding size).\n",
    "        d_ff (int): Hidden dimensionality (usually larger, e.g., 2048 in original paper).\n",
    "\n",
    "    Architecture:\n",
    "        FFN(x) = max(0, xW1 + b1)W2 + b2\n",
    "               = fc2(ReLU(fc1(x)))\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)   # First linear transformation (expands dimension)\n",
    "        self.relu = nn.ReLU()                 # Activation function\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)   # Second linear transformation (projects back to d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))  # Apply FFN to each position independently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79dc609d",
   "metadata": {
    "_cell_guid": "c9046eff-e5e5-4a82-8ae7-e283f6da1639",
    "_uuid": "0c39367a-bced-43a1-a720-3d7e6f8a4e08",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:06.674131Z",
     "iopub.status.busy": "2025-06-26T19:24:06.673931Z",
     "iopub.status.idle": "2025-06-26T19:24:06.678953Z",
     "shell.execute_reply": "2025-06-26T19:24:06.678302Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014387,
     "end_time": "2025-06-26T19:24:06.679942",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.665555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    A single Transformer encoder block.\n",
    "\n",
    "    Consists of:\n",
    "    1. Multi-head self-attention layer with residual connection + LayerNorm\n",
    "    2. Position-wise feed-forward network with residual connection + LayerNorm\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Input/output embedding dimension.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        d_ff (int): Hidden layer size in the feed-forward network.\n",
    "        dropout (float): Dropout rate applied after attention and FFN.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Multi-head self-attention\n",
    "        self.attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        # Position-wise feed-forward network\n",
    "        self.ff_sublayer = FeedForwardSubLayer(d_model, d_ff)\n",
    "\n",
    "        # Layer normalizations for residual connections\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, src_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, seq_len, d_model)\n",
    "            src_mask: Optional mask for self-attention (batch_size, seq_len, seq_len)\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "\n",
    "        # === Sublayer 1: Multi-Head Self-Attention ===\n",
    "        attn_output = self.attn(x, x, x, src_mask)  # Q = K = V = x\n",
    "        x = self.norm1(x + self.dropout(attn_output))  # Add & Norm\n",
    "\n",
    "        # === Sublayer 2: Feed-Forward ===\n",
    "        ff_output = self.ff_sublayer(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))  # Add & Norm\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd15bda",
   "metadata": {
    "papermill": {
     "duration": 0.007733,
     "end_time": "2025-06-26T19:24:06.695400",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.687667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Encoder Layer\n",
    "A Transformer Encoder Layer is a single block in the stack of encoder blocks used in models like BERT, GPT (decoder-only variant), and the original Transformer. Each layer processes a sequence of tokens to build richer, context-aware representations.\n",
    "\n",
    "Encoder-only transformers simplify this architecture to place greater emphasis on understanding and representing the input data, such as text classification. \n",
    "\n",
    "They have two main components: \n",
    "- Each encoder layer incorporates a multi-head self-attention mechanism to capture relationships between tokens in the sequence\n",
    "\n",
    "- followed by feed-forward sublayers to map this knowledge into abstract, nonlinear representations. Both elements are usually combined with other techniques like layer normalizations and dropouts to improve training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66faac5a",
   "metadata": {
    "_cell_guid": "f03355df-3def-4f8c-a562-1a1ff6ff68e1",
    "_uuid": "ebf78e2c-77bc-438e-8637-d0c16882dda8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:06.711806Z",
     "iopub.status.busy": "2025-06-26T19:24:06.711614Z",
     "iopub.status.idle": "2025-06-26T19:24:06.716665Z",
     "shell.execute_reply": "2025-06-26T19:24:06.716014Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014433,
     "end_time": "2025-06-26T19:24:06.717686",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.703253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Full Transformer Encoder stack composed of:\n",
    "    - Input token embeddings\n",
    "    - Positional encodings\n",
    "    - N stacked encoder layers\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of the input vocabulary.\n",
    "        d_model (int): Embedding dimension.\n",
    "        num_layers (int): Number of encoder layers to stack.\n",
    "        num_heads (int): Number of attention heads in each layer.\n",
    "        d_ff (int): Hidden layer size in feed-forward network.\n",
    "        dropout (float): Dropout rate for regularization.\n",
    "        max_seq_length (int): Maximum input sequence length.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length):\n",
    "        super().__init__()\n",
    "\n",
    "        # Token embedding + positional encoding\n",
    "        self.embedding = InputEmbeddings(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        # Stack of N encoder layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, src_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): Input token IDs, shape (batch_size, seq_len)\n",
    "            src_mask (Tensor or None): Attention mask, shape (batch_size, seq_len, seq_len)\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Encoded representation, shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        # Embed token IDs and add positional information\n",
    "        x = self.embedding(x)                          # (batch_size, seq_len, d_model)\n",
    "        x = self.positional_encoding(x)                # (batch_size, seq_len, d_model)\n",
    "\n",
    "        # Pass through each encoder layer\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081e640a",
   "metadata": {
    "papermill": {
     "duration": 0.007714,
     "end_time": "2025-06-26T19:24:06.733486",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.725772",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "we can create a classification head, suitable for tasks like text classification and sentiment analysis. \n",
    "It consists of a linear layer with softmax activation to map the resulting encoder hidden states into class probabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5b64a1",
   "metadata": {
    "papermill": {
     "duration": 0.007626,
     "end_time": "2025-06-26T19:24:06.748983",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.741357",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Classification Head\n",
    "\n",
    "- **Tasks** : Text Classification, Sentiment Analysis, NER Recognition, Extractive QA and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92bfcdea",
   "metadata": {
    "_cell_guid": "e00f2d0f-e0cb-499c-8bb7-b0aeaae19d3d",
    "_uuid": "8e43286a-06c9-463e-b1d6-697bb311321d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:06.765422Z",
     "iopub.status.busy": "2025-06-26T19:24:06.765199Z",
     "iopub.status.idle": "2025-06-26T19:24:06.769530Z",
     "shell.execute_reply": "2025-06-26T19:24:06.768863Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013916,
     "end_time": "2025-06-26T19:24:06.770780",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.756864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClassifierHead(nn.Module):\n",
    "    def __init__(self, d_model, num_classes):\n",
    "        \"\"\"\n",
    "        Classification head for the Transformer model.\n",
    "\n",
    "        Args:\n",
    "            d_model (int): The dimensionality of the input features (usually\n",
    "                           the hidden size of the Transformer encoder).\n",
    "            num_classes (int): Number of output classes for classification.\n",
    "\n",
    "        Components:\n",
    "            - A single fully connected (linear) layer that maps the Transformer\n",
    "              output feature vector to class logits.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(d_model, num_classes)  # Linear layer from d_model to num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch_size, d_model) or\n",
    "                        possibly (batch_size, seq_len, d_model) if sequence output\n",
    "                        is passed directly.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Raw logits of shape (batch_size, num_classes).\n",
    "\n",
    "        Note:\n",
    "            - If input is (batch_size, seq_len, d_model), you typically want to\n",
    "              pool or select a token representation (e.g., mean pooling or first token)\n",
    "              before passing here.\n",
    "            - This layer returns raw logits (no activation), which is compatible with\n",
    "              loss functions like nn.CrossEntropyLoss.\n",
    "        \"\"\"\n",
    "        return self.fc(x)  # Output logits for each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9216a6eb",
   "metadata": {
    "_cell_guid": "9450ed57-3a67-42ba-ba82-3cce6a612586",
    "_uuid": "1023d25c-0771-4d9d-9698-2ce88ccc96c8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:06.787464Z",
     "iopub.status.busy": "2025-06-26T19:24:06.787256Z",
     "iopub.status.idle": "2025-06-26T19:24:06.791780Z",
     "shell.execute_reply": "2025-06-26T19:24:06.791083Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014339,
     "end_time": "2025-06-26T19:24:06.793066",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.778727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length, num_classes):\n",
    "        super().__init__()\n",
    "        # Transformer encoder to get contextual embeddings\n",
    "        self.encoder = TransformerEncoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)\n",
    "        # Simple classification head\n",
    "        self.classifier = ClassifierHead(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x, src_mask=None):\n",
    "        # Encode input tokens: output shape (batch_size, seq_len, d_model)\n",
    "        encoder_output = self.encoder(x, src_mask)\n",
    "\n",
    "        # Take the first token's embedding as aggregate representation (CLS token)\n",
    "        cls_token_embedding = encoder_output[:, 0, :]  # shape (batch_size, d_model)\n",
    "\n",
    "        # Classify using the CLS token embedding\n",
    "        logits = self.classifier(cls_token_embedding)  # shape (batch_size, num_classes)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69c1e733",
   "metadata": {
    "_cell_guid": "e6bbd09a-6fc0-405a-bc21-50f446d230ad",
    "_uuid": "d4d0ae2c-8995-4090-ac79-528ca468bf1e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:06.809419Z",
     "iopub.status.busy": "2025-06-26T19:24:06.809221Z",
     "iopub.status.idle": "2025-06-26T19:24:30.904374Z",
     "shell.execute_reply": "2025-06-26T19:24:30.903776Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 24.104758,
     "end_time": "2025-06-26T19:24:30.905701",
     "exception": false,
     "start_time": "2025-06-26T19:24:06.800943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example: assuming df with 'text' and 'label' columns already available\n",
    "texts = df['news'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "\n",
    "# Your vocab & input length\n",
    "max_seq_length = 32\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "\n",
    "# Build vocab with minimum frequency 5 to reduce vocab size\n",
    "word2idx = build_vocab(texts, min_freq=1)\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "embedding_layer = InputEmbeddings(vocab_size=vocab_size, d_model=d_model)\n",
    "positional_encoding_layer = PositionalEncoding(d_model=d_model, max_seq_length=max_seq_length)\n",
    "mha_layer = MultiHeadAttention(d_model, num_heads).to(device)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "embedding_layer = embedding_layer.to(device)\n",
    "positional_encoding_layer = positional_encoding_layer.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2337f",
   "metadata": {
    "papermill": {
     "duration": 0.007777,
     "end_time": "2025-06-26T19:24:30.922202",
     "exception": false,
     "start_time": "2025-06-26T19:24:30.914425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Check the Embeddings, Encoding and MHA Shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b20219a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:30.938455Z",
     "iopub.status.busy": "2025-06-26T19:24:30.938254Z",
     "iopub.status.idle": "2025-06-26T19:24:31.274400Z",
     "shell.execute_reply": "2025-06-26T19:24:31.273533Z"
    },
    "papermill": {
     "duration": 0.345797,
     "end_time": "2025-06-26T19:24:31.275646",
     "exception": false,
     "start_time": "2025-06-26T19:24:30.929849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([64, 32])\n",
      "Embedding shape: torch.Size([64, 32, 512])\n",
      "After Positional Encoding: torch.Size([64, 32, 512])\n",
      "MHA Output shape: torch.Size([64, 32, 512])\n"
     ]
    }
   ],
   "source": [
    "dataset = NewsDataset(texts, labels, word2idx, max_seq_length)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Take one batch from your real dataset\n",
    "for batch_inputs, batch_labels in dataloader:\n",
    "    batch_inputs = batch_inputs.to(device)\n",
    "\n",
    "    # Step 1: Embed input token IDs\n",
    "    embedding_output = embedding_layer(batch_inputs)  # (B, L, D)\n",
    "\n",
    "    # Step 2: Add positional encoding\n",
    "    encoding_output = positional_encoding_layer(embedding_output)  # (B, L, D)\n",
    "\n",
    "    # Step 3: Apply Multi-Head Attention (Self-attention)\n",
    "    output = mha_layer(encoding_output, encoding_output, encoding_output)  # (B, L, D)\n",
    "\n",
    "    print(\"Input shape:\", batch_inputs.shape)\n",
    "    print(\"Embedding shape:\", embedding_output.shape)\n",
    "    print(\"After Positional Encoding:\", encoding_output.shape)\n",
    "    print(\"MHA Output shape:\", output.shape)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f95cbe",
   "metadata": {
    "papermill": {
     "duration": 0.007806,
     "end_time": "2025-06-26T19:24:31.291983",
     "exception": false,
     "start_time": "2025-06-26T19:24:31.284177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Split the dataset into Train and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae1403f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:31.308597Z",
     "iopub.status.busy": "2025-06-26T19:24:31.308378Z",
     "iopub.status.idle": "2025-06-26T19:24:31.326017Z",
     "shell.execute_reply": "2025-06-26T19:24:31.325223Z"
    },
    "papermill": {
     "duration": 0.027182,
     "end_time": "2025-06-26T19:24:31.327102",
     "exception": false,
     "start_time": "2025-06-26T19:24:31.299920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "dataset = NewsDataset(texts, labels, word2idx, max_len=max_seq_length)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b1218",
   "metadata": {
    "papermill": {
     "duration": 0.007627,
     "end_time": "2025-06-26T19:24:31.342673",
     "exception": false,
     "start_time": "2025-06-26T19:24:31.335046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38dcd4ee",
   "metadata": {
    "_cell_guid": "7c512d2a-7df6-431e-8ecc-f5a057bfe80a",
    "_uuid": "c030f590-2589-4ece-88a0-896dac53c08d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:31.359339Z",
     "iopub.status.busy": "2025-06-26T19:24:31.358752Z",
     "iopub.status.idle": "2025-06-26T19:24:36.449849Z",
     "shell.execute_reply": "2025-06-26T19:24:36.449075Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 5.100928,
     "end_time": "2025-06-26T19:24:36.451337",
     "exception": false,
     "start_time": "2025-06-26T19:24:31.350409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = 42\n",
    "\n",
    "model = TransformerClassifier(\n",
    "    vocab_size=len(word2idx),\n",
    "    d_model=512,\n",
    "    num_layers=2,\n",
    "    num_heads=8,\n",
    "    d_ff=2048,\n",
    "    dropout=0.1,\n",
    "    max_seq_length=32,\n",
    "    num_classes=num_classes  # number of categories\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor.to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f85eae",
   "metadata": {
    "papermill": {
     "duration": 0.008824,
     "end_time": "2025-06-26T19:24:36.469180",
     "exception": false,
     "start_time": "2025-06-26T19:24:36.460356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e08849c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:36.487296Z",
     "iopub.status.busy": "2025-06-26T19:24:36.486455Z",
     "iopub.status.idle": "2025-06-26T19:24:36.491929Z",
     "shell.execute_reply": "2025-06-26T19:24:36.491330Z"
    },
    "papermill": {
     "duration": 0.01558,
     "end_time": "2025-06-26T19:24:36.493036",
     "exception": false,
     "start_time": "2025-06-26T19:24:36.477456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()  # set eval mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # no gradients needed\n",
    "        for batch_inputs, batch_labels in dataloader:\n",
    "            batch_inputs = batch_inputs.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            outputs = model(batch_inputs)  # forward pass\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "\n",
    "            running_loss += loss.item() * batch_inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            correct += (predicted == batch_labels).sum().item()\n",
    "            total += batch_inputs.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fab485",
   "metadata": {
    "papermill": {
     "duration": 0.007945,
     "end_time": "2025-06-26T19:24:36.508914",
     "exception": false,
     "start_time": "2025-06-26T19:24:36.500969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b5277e7",
   "metadata": {
    "_cell_guid": "40422247-83bf-42cc-a843-e6b776ad5665",
    "_uuid": "6e15702f-1d6a-4d2f-88ac-02910f232ef3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-26T19:24:36.526881Z",
     "iopub.status.busy": "2025-06-26T19:24:36.526632Z",
     "iopub.status.idle": "2025-06-26T19:35:01.916098Z",
     "shell.execute_reply": "2025-06-26T19:35:01.915244Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 625.399981,
     "end_time": "2025-06-26T19:35:01.917342",
     "exception": false,
     "start_time": "2025-06-26T19:24:36.517361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 — Train Loss: 2.9705, Train Acc: 0.2301 | Val Loss: 2.4400, Val Acc: 0.3576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 — Train Loss: 2.1419, Train Acc: 0.4068 | Val Loss: 2.1868, Val Acc: 0.4152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 — Train Loss: 1.7706, Train Acc: 0.4711 | Val Loss: 2.0930, Val Acc: 0.4352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 — Train Loss: 1.4915, Train Acc: 0.5178 | Val Loss: 2.1030, Val Acc: 0.4573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 — Train Loss: 1.2416, Train Acc: 0.5624 | Val Loss: 2.1703, Val Acc: 0.4629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 — Train Loss: 1.0319, Train Acc: 0.6047 | Val Loss: 2.2474, Val Acc: 0.4684\n",
      "Early stopping at epoch 6 due to no improvement in val loss.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "num_epochs = 20\n",
    "patience = 3  # stop if no improvement for 3 consecutive epochs\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    loop = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "    for batch_inputs, batch_labels in loop:\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)  # logits (batch_size, num_classes)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * batch_inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "        total += batch_inputs.size(0)\n",
    "\n",
    "        loop.set_postfix(loss=loss.item(), accuracy=correct/total)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    # Validation step - define this function yourself or inline\n",
    "    val_loss, val_acc = evaluate(model, val_dataloader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} — Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save best model if needed\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1} due to no improvement in val loss.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08ae4950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T19:35:03.745136Z",
     "iopub.status.busy": "2025-06-26T19:35:03.744525Z",
     "iopub.status.idle": "2025-06-26T19:35:03.748421Z",
     "shell.execute_reply": "2025-06-26T19:35:03.747696Z"
    },
    "papermill": {
     "duration": 0.963205,
     "end_time": "2025-06-26T19:35:03.749533",
     "exception": false,
     "start_time": "2025-06-26T19:35:02.786328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx2label = {i: label for i, label in enumerate(le.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d452ba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T19:35:05.606652Z",
     "iopub.status.busy": "2025-06-26T19:35:05.606071Z",
     "iopub.status.idle": "2025-06-26T19:35:05.611711Z",
     "shell.execute_reply": "2025-06-26T19:35:05.610974Z"
    },
    "papermill": {
     "duration": 0.924528,
     "end_time": "2025-06-26T19:35:05.612949",
     "exception": false,
     "start_time": "2025-06-26T19:35:04.688421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_category(text, model, word2idx, idx2label, max_len=32, device='cpu'):\n",
    "    model.eval()\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    token_ids = [word2idx.get(token, word2idx['<UNK>']) for token in tokens]\n",
    "\n",
    "    # Padding\n",
    "    if len(token_ids) < max_len:\n",
    "        token_ids += [word2idx['<PAD>']] * (max_len - len(token_ids))\n",
    "    else:\n",
    "        token_ids = token_ids[:max_len]\n",
    "\n",
    "    input_tensor = torch.tensor([token_ids], dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)  # shape: (1, num_classes)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pred_class = torch.argmax(probs, dim=1).item()\n",
    "\n",
    "    return idx2label[pred_class], probs.cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e113110a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T19:35:07.404512Z",
     "iopub.status.busy": "2025-06-26T19:35:07.403741Z",
     "iopub.status.idle": "2025-06-26T19:35:07.407549Z",
     "shell.execute_reply": "2025-06-26T19:35:07.406958Z"
    },
    "papermill": {
     "duration": 0.87204,
     "end_time": "2025-06-26T19:35:07.408632",
     "exception": false,
     "start_time": "2025-06-26T19:35:06.536592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx2label = {i: label for i, label in enumerate(le.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3c84f5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T19:35:09.286771Z",
     "iopub.status.busy": "2025-06-26T19:35:09.286206Z",
     "iopub.status.idle": "2025-06-26T19:35:09.339559Z",
     "shell.execute_reply": "2025-06-26T19:35:09.338577Z"
    },
    "papermill": {
     "duration": 0.985359,
     "end_time": "2025-06-26T19:35:09.340858",
     "exception": false,
     "start_time": "2025-06-26T19:35:08.355499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The economy is showing signs of recovery after a challenging year.\n",
      "Predicted category: BUSINESS\n",
      "Probabilities: [7.1672985e-05 6.2448024e-05 4.0127542e-03 5.0124645e-01 3.9949510e-04\n",
      " 2.8582654e-04 1.1320011e-03 2.3961327e-05 4.7754154e-05 4.5505296e-03\n",
      " 2.3165389e-04 8.0711935e-03 7.7646480e-05 2.0634379e-05 5.2365763e-03\n",
      " 2.2581477e-01 7.2665550e-03 7.0395108e-05 1.2457173e-01 1.2219480e-03\n",
      " 6.0723198e-04 1.3797791e-02 1.7507903e-04 1.1187567e-03 3.3984665e-02\n",
      " 7.3305513e-05 2.6453963e-05 1.4153704e-04 1.6003679e-03 7.1123155e-05\n",
      " 1.8926252e-05 3.2589879e-04 7.6379399e-03 8.2760658e-03 2.0206635e-04\n",
      " 1.3346942e-03 9.6809381e-06 2.4740578e-04 6.1990658e-04 5.9244683e-04\n",
      " 2.6351145e-02 1.8371470e-02]\n",
      "\n",
      "Text: New breakthrough in cancer research offers hope for many patients.\n",
      "Predicted category: HEALTHY LIVING\n",
      "Probabilities: [1.7785391e-05 6.7837021e-07 1.0860733e-04 2.5166050e-03 3.2954402e-02\n",
      " 1.8130962e-04 2.8438328e-05 3.6480219e-06 1.8190220e-05 4.6419227e-03\n",
      " 4.2989021e-05 8.6665976e-05 5.4675033e-03 2.6124115e-05 1.6817212e-04\n",
      " 3.9077611e-03 8.5604769e-01 4.2520469e-06 3.7506405e-02 9.3527997e-05\n",
      " 2.7594081e-04 9.6063650e-06 2.2575694e-04 3.0467741e-04 2.3879262e-03\n",
      " 7.2607561e-03 9.5332763e-04 2.8876210e-02 7.3376152e-04 2.5746707e-05\n",
      " 6.1000305e-06 2.2165414e-05 3.2224350e-05 7.7737350e-05 3.9164948e-05\n",
      " 1.2544246e-05 1.2256581e-05 9.5375130e-05 1.3189589e-02 1.5104894e-03\n",
      " 1.8360182e-05 1.0750870e-04]\n",
      "\n",
      "Text: The government has announced new policies to tackle climate change.\n",
      "Predicted category: GREEN\n",
      "Probabilities: [1.60853728e-04 5.41620557e-06 9.52508417e-04 2.01473804e-03\n",
      " 2.71911176e-05 4.00760304e-03 2.20286511e-05 1.01591731e-05\n",
      " 8.24707456e-07 2.88295996e-04 1.24742265e-03 7.44294235e-03\n",
      " 5.27434668e-06 1.06678177e-04 1.30999717e-03 8.99525702e-01\n",
      " 1.53676001e-03 1.51046925e-05 1.28218839e-02 7.24280253e-05\n",
      " 1.47533156e-02 1.35616176e-06 1.21871026e-05 1.24976359e-04\n",
      " 2.27571651e-02 7.13997928e-04 2.42739823e-03 6.04179688e-03\n",
      " 2.56783096e-03 3.93988339e-05 4.68202325e-06 9.26774694e-04\n",
      " 2.47404608e-03 4.84351942e-04 2.47665419e-04 9.17814032e-05\n",
      " 5.17942169e-07 4.33363602e-04 3.35302757e-05 1.29386986e-04\n",
      " 1.04614627e-03 1.31144971e-02]\n",
      "\n",
      "Text: The latest smartphone model features a stunning new design.\n",
      "Predicted category: STYLE\n",
      "Probabilities: [1.71292305e-01 3.63578583e-04 1.46321179e-02 2.28095762e-02\n",
      " 4.15418981e-05 7.49734289e-04 8.48345007e-05 4.04167164e-04\n",
      " 2.85757633e-05 2.71360768e-04 1.33324806e-02 6.86704807e-05\n",
      " 5.09780645e-03 1.31146997e-04 5.70917735e-04 3.21011408e-03\n",
      " 1.47455027e-02 2.13313960e-02 7.03993952e-03 6.02823857e-04\n",
      " 7.46499887e-03 2.18608664e-04 1.26204657e-04 1.07824325e-03\n",
      " 1.19774253e-03 3.91488895e-03 1.31147492e-04 1.95867717e-04\n",
      " 4.91547806e-04 5.79258680e-01 6.77211350e-03 1.01180654e-03\n",
      " 1.17260516e-01 9.75217699e-06 1.24403299e-03 4.13023881e-05\n",
      " 2.16894296e-05 1.07079701e-04 4.32281697e-04 2.55644030e-04\n",
      " 1.27065305e-05 1.94458396e-03]\n",
      "\n",
      "Text: Local sports team wins championship after a thrilling final match.\n",
      "Predicted category: SPORTS\n",
      "Probabilities: [1.06665107e-06 1.47460213e-07 6.83952821e-05 3.48885078e-05\n",
      " 3.92117499e-06 1.98515452e-04 8.34416187e-06 4.47430573e-08\n",
      " 9.20422636e-08 2.41634041e-07 3.99167620e-05 2.45763403e-07\n",
      " 7.33807724e-07 1.63632740e-05 3.92978545e-04 6.91173091e-06\n",
      " 1.12260705e-05 7.09621375e-08 3.33657626e-05 9.17262412e-07\n",
      " 1.13289047e-04 2.70295402e-07 6.07846346e-07 2.45396659e-05\n",
      " 9.47132867e-06 5.58426691e-05 3.18319303e-06 2.41625185e-06\n",
      " 9.98131931e-01 2.06215441e-06 2.31875802e-07 5.56716113e-05\n",
      " 2.74024096e-05 3.10729615e-06 1.98703151e-06 9.07303388e-07\n",
      " 1.35499320e-07 7.18314433e-04 6.99308714e-07 2.82833389e-05\n",
      " 9.50840274e-07 4.20075480e-07]\n",
      "\n",
      "Text: Artists around the world gather to celebrate cultural diversity.\n",
      "Predicted category: ARTS\n",
      "Probabilities: [9.8006433e-01 7.2260452e-03 1.4843320e-04 2.0361051e-05 5.7987141e-05\n",
      " 1.2482859e-05 1.0979063e-05 3.8487534e-04 3.6076730e-07 2.9685818e-05\n",
      " 7.3837041e-04 1.9910280e-07 4.8770587e-05 2.1749045e-06 5.4792198e-04\n",
      " 2.7891952e-05 5.3967498e-05 1.6002641e-06 1.1806384e-04 7.8187296e-03\n",
      " 4.1058029e-05 8.0368736e-08 1.9566817e-06 3.2659370e-04 9.9932804e-06\n",
      " 1.2469642e-03 8.9318790e-05 1.0877194e-06 6.8137240e-05 2.5844239e-04\n",
      " 1.3523958e-06 9.7771872e-06 2.9211009e-05 1.4654372e-05 2.0855344e-04\n",
      " 2.0022521e-06 9.5773395e-08 2.0479171e-04 1.0909628e-06 3.1136115e-05\n",
      " 6.7853180e-06 1.3357542e-04]\n",
      "\n",
      "Text: The fashion industry is embracing sustainable and eco-friendly materials.\n",
      "Predicted category: STYLE\n",
      "Probabilities: [6.9531106e-04 6.2319250e-06 1.2853164e-03 1.9094541e-04 7.4832218e-07\n",
      " 1.0530590e-05 2.6068296e-06 1.0952393e-06 5.3313141e-07 1.6412032e-05\n",
      " 2.9873062e-04 6.2132972e-06 6.4346188e-04 2.7133650e-05 8.6186865e-06\n",
      " 2.4552937e-05 1.8453995e-04 1.2367811e-04 1.2505367e-04 2.3042584e-04\n",
      " 5.3444155e-04 1.0449408e-05 4.7154813e-06 2.1284270e-05 5.3961863e-05\n",
      " 1.4969964e-03 6.4118707e-05 8.6167138e-06 9.1161484e-05 9.7506410e-01\n",
      " 1.7822223e-02 2.6659663e-05 1.5990017e-06 9.9294930e-06 3.9456098e-04\n",
      " 6.8182471e-06 6.3877833e-06 2.4846127e-05 4.4133922e-05 2.3978611e-05\n",
      " 2.3424556e-05 3.8355717e-04]\n",
      "\n",
      "Text: A new cafe in town offers delicious vegan options.\n",
      "Predicted category: TASTE\n",
      "Probabilities: [4.8845410e-03 4.9717538e-04 4.0475908e-03 5.1058494e-03 2.0466966e-04\n",
      " 3.7074322e-03 1.0250649e-04 2.5928751e-04 2.0892028e-04 2.3241452e-04\n",
      " 5.8714775e-03 2.6822570e-04 8.2783615e-03 1.9093988e-02 8.7382831e-02\n",
      " 8.8481698e-03 1.0185543e-01 4.3777772e-04 1.2914474e-02 3.0631502e-04\n",
      " 6.4896105e-04 2.8469043e-05 3.0753840e-04 9.4982563e-03 1.3810815e-03\n",
      " 2.5305437e-02 1.4288408e-03 4.4282340e-03 1.3204645e-03 3.2868478e-02\n",
      " 4.3214980e-04 5.3240973e-01 1.2865437e-04 9.9852006e-04 8.5548103e-02\n",
      " 4.2852433e-05 1.0275843e-04 3.1269927e-02 3.1968111e-03 1.8995353e-03\n",
      " 1.7861038e-04 2.0690951e-03]\n",
      "\n",
      "Text: The education system is evolving to include more technology in classrooms.\n",
      "Predicted category: EDUCATION\n",
      "Probabilities: [5.4905053e-05 2.2102240e-05 4.0149555e-04 4.8768386e-04 1.5012899e-02\n",
      " 1.8315888e-05 1.9529038e-05 1.1326766e-05 2.7266975e-05 9.6420860e-01\n",
      " 9.7938837e-06 9.2923328e-06 3.1435255e-05 1.9338902e-05 3.4300887e-05\n",
      " 5.8517767e-06 2.2898412e-03 4.8594102e-06 1.4092303e-02 2.8942397e-05\n",
      " 9.0469657e-06 2.0231637e-05 3.8107863e-04 2.2752216e-04 7.3513555e-05\n",
      " 5.8131052e-05 2.0537387e-05 2.2895843e-05 1.5030491e-05 2.3254317e-05\n",
      " 8.3306331e-06 5.0328053e-05 1.1108185e-03 5.0517774e-06 5.6219660e-06\n",
      " 3.9218430e-06 5.3445660e-06 4.2428246e-06 5.7006039e-04 5.7764794e-04\n",
      " 1.0864562e-05 6.3550733e-06]\n",
      "\n",
      "Text: Travel restrictions have eased, boosting tourism worldwide.\n",
      "Predicted category: TRAVEL\n",
      "Probabilities: [9.48362722e-05 6.35184097e-06 4.28048443e-05 2.21730000e-03\n",
      " 6.40521641e-04 4.44453955e-03 1.06330568e-04 2.12228988e-05\n",
      " 1.23354375e-05 3.50246648e-03 5.77430706e-04 7.74488910e-07\n",
      " 3.51633923e-03 6.10309374e-03 2.34083482e-03 2.96467857e-04\n",
      " 4.70492849e-03 1.11496520e-04 1.47233822e-03 1.06463805e-04\n",
      " 2.62811780e-04 1.84837045e-05 5.26178774e-05 7.49229977e-04\n",
      " 2.10335362e-03 4.12854977e-04 1.15364126e-03 2.20277929e-04\n",
      " 1.78457540e-05 1.46864142e-04 1.12585527e-04 1.66331362e-02\n",
      " 4.58874536e-04 4.87031830e-05 9.38751698e-01 3.17635386e-05\n",
      " 7.76487941e-05 7.96903484e-03 5.25644609e-05 7.38073795e-05\n",
      " 1.63444965e-05 3.16768710e-04]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts_to_predict = [\n",
    "    \"The economy is showing signs of recovery after a challenging year.\",\n",
    "    \"New breakthrough in cancer research offers hope for many patients.\",\n",
    "    \"The government has announced new policies to tackle climate change.\",\n",
    "    \"The latest smartphone model features a stunning new design.\",\n",
    "    \"Local sports team wins championship after a thrilling final match.\",\n",
    "    \"Artists around the world gather to celebrate cultural diversity.\",\n",
    "    \"The fashion industry is embracing sustainable and eco-friendly materials.\",\n",
    "    \"A new cafe in town offers delicious vegan options.\",\n",
    "    \"The education system is evolving to include more technology in classrooms.\",\n",
    "    \"Travel restrictions have eased, boosting tourism worldwide.\"\n",
    "]\n",
    "\n",
    "for text in texts_to_predict:\n",
    "    predicted_category, probabilities = predict_category(text, model, word2idx, idx2label, max_len=32, device=device)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted category: {predicted_category}\")\n",
    "    print(f\"Probabilities: {probabilities}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b26aa81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T19:35:11.185510Z",
     "iopub.status.busy": "2025-06-26T19:35:11.185203Z",
     "iopub.status.idle": "2025-06-26T19:35:11.189477Z",
     "shell.execute_reply": "2025-06-26T19:35:11.188763Z"
    },
    "papermill": {
     "duration": 0.920873,
     "end_time": "2025-06-26T19:35:11.190554",
     "exception": false,
     "start_time": "2025-06-26T19:35:10.269681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def top_k_categories(probs, idx2label, k=3):\n",
    "    topk_idx = np.argsort(probs)[::-1][:k]\n",
    "    return [(idx2label[i], probs[i]) for i in topk_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "448376c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T19:35:13.020076Z",
     "iopub.status.busy": "2025-06-26T19:35:13.019393Z",
     "iopub.status.idle": "2025-06-26T19:35:13.024573Z",
     "shell.execute_reply": "2025-06-26T19:35:13.023789Z"
    },
    "papermill": {
     "duration": 0.976065,
     "end_time": "2025-06-26T19:35:13.025714",
     "exception": false,
     "start_time": "2025-06-26T19:35:12.049649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TRAVEL', 0.9387517), ('TASTE', 0.016633136), ('WEIRD NEWS', 0.007969035)]\n"
     ]
    }
   ],
   "source": [
    "top3 = top_k_categories(probabilities, idx2label)\n",
    "print(top3)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 32526,
     "sourceId": 4243451,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7749426,
     "sourceId": 12295250,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 689.820846,
   "end_time": "2025-06-26T19:35:17.154809",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-26T19:23:47.333963",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
